{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "FILE_PATH = '../datasets/cylinder/'\n",
    "OUTDIR = '../models/cylinder'\n",
    "DATASET = FILE_PATH + 'cylinder.csv'\n",
    "TRAIN_SET = FILE_PATH + 'cylinder.train.csv'\n",
    "VALIDATION_SET = FILE_PATH + 'cylinder.validation.csv'\n",
    "TEST_SET = FILE_PATH + 'cylinder.test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(count):\n",
    "    ndata = np.random.rand(count, 2) * 1.5 + 0.5\n",
    "    df = pd.DataFrame(data=ndata, columns=['Radius', 'Height'])\n",
    "    df['Volume'] = 3.14 * df['Radius'] * df['Radius'] * df['Height']\n",
    "    df.to_csv(DATASET, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_data(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATASET)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def split(df):\n",
    "    train_ratio = 0.7\n",
    "    test_validation_ratio = 0.15\n",
    "    df_with_id = df\n",
    "    df_with_id['Id'] = df_with_id['Radius'] * 1000 + df_with_id['Height']\n",
    "    \n",
    "    train_set, temp_set = df_split(df_with_id, train_ratio, 'Id')\n",
    "    validation_set, test_set = df_split(temp_set, test_validation_ratio, 'Id')\n",
    "    \n",
    "    train_set.drop('Id', axis=1, inplace=True)\n",
    "    validation_set.drop('Id', axis=1, inplace=True)\n",
    "    test_set.drop('Id', axis=1, inplace=True)\n",
    "    \n",
    "    train_set.to_csv(TRAIN_SET, index=False)\n",
    "    validation_set.to_csv(VALIDATION_SET, index=False)\n",
    "    test_set.to_csv(TEST_SET, index=False)\n",
    "    \n",
    "\n",
    "def test_set_check(identifier, ratio, hash):\n",
    "    return hash(np.int64(identifier)).digest()[-1] < 256 * ratio\n",
    "    \n",
    "def df_split(data, ratio, id_column, hash=hashlib.md5):\n",
    "    ids = data[id_column]\n",
    "    in_test_set = ids.apply(lambda id_: test_set_check(id_, ratio, hash))\n",
    "    return data.loc[~in_test_set], data.loc[in_test_set]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "CSV_COLUMNS = ['Radius', 'Height', 'Volume']\n",
    "FEATURES = CSV_COLUMNS[0:len(CSV_COLUMNS) - 1]\n",
    "LABEL = CSV_COLUMNS[len(CSV_COLUMNS) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(TRAIN_SET)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = pd.read_csv(VALIDATION_SET)\n",
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(TEST_SET)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plot\n",
    "plot.style.use(['dark_background'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.plot(kind='scatter', x='Radius', y='Volume', figsize=(10,10), alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.plot(kind='scatter', x='Height', y='Volume', figsize=(10,10), alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_input_fn(df, num_epochs):\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "        x=df,\n",
    "        y=df[LABEL],\n",
    "        batch_size=128,\n",
    "        num_epochs=num_epochs,\n",
    "        shuffle=True,\n",
    "        queue_capacity=1000\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_eval_input_fn(df):\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "        x=df,\n",
    "        y=df[LABEL],\n",
    "        batch_size=128,\n",
    "        shuffle=False,\n",
    "        queue_capacity=1000\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction_input_fn(df):\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "        x=df,\n",
    "        y=None,\n",
    "        batch_size=128,\n",
    "        shuffle=False,\n",
    "        queue_capacity=1000\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_cols():\n",
    "    input_columns = [tf.feature_column.numeric_column(k) for k in FEATURES]\n",
    "    return input_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "\n",
    "model = tf.estimator.DNNRegressor(\n",
    "    hidden_units = [32, 8, 2],\n",
    "    feature_columns = make_feature_cols(), \n",
    "    model_dir = OUTDIR)\n",
    "\n",
    "model.train(input_fn = make_train_input_fn(df_train, num_epochs = 100));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_rmse(model, df):\n",
    "    metrics = model.evaluate(input_fn=make_eval_input_fn(df))\n",
    "    print('RMSE on dataset = {}'.format(np.sqrt(metrics['average_loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_rmse(model, df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(input_fn = make_prediction_input_fn(df_test))\n",
    "for items in predictions:\n",
    "    print(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = pd.DataFrame(\n",
    "    data=[[1.0, 1.0],[2.0,2.0]],\n",
    "    columns=FEATURES\n",
    ")\n",
    "\n",
    "df_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(input_fn = make_prediction_input_fn(df_predict))\n",
    "\n",
    "for item in results:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
